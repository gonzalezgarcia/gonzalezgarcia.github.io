<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="esp"><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="esp" /><updated>2024-05-15T19:31:17+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">test</title><subtitle></subtitle><entry><title type="html">How do we keep track of action plans?</title><link href="http://localhost:4000/blog/2024/2p2d/" rel="alternate" type="text/html" title="How do we keep track of action plans?" /><published>2024-03-01T00:00:00+01:00</published><updated>2024-03-01T00:00:00+01:00</updated><id>http://localhost:4000/blog/2024/2p2d</id><content type="html" xml:base="http://localhost:4000/blog/2024/2p2d/"><![CDATA[<p><a href="https://t.co/mNXBW2q6sW">üîì Open access</a></p>

<p>Recent research shows that items held in WM are dynamically prioritized, shifting between active and latent states according to their behavioral relevance. Our work aimed to extend these results, based on visual information, to more complex action plans maintained in WM.</p>

<p>In our task, participants coded sets of novel S-R mappings whose task relevance was parametrically manipulated with retrocues. Then, we quantified (in accuracy rates and DDM parameters) the interference exerted among mappings as a proxy of distinct functional WM states.</p>

<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2p2d_1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<p>We showed that the more likely an S-R mapping is to become relevant, the greater its interference with ongoing behavior, evidencing flexible prioritization in WM. These results further suggest that functional states are held in non-orthogonal codes, prone to interference.</p>

<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2p2d_2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<p>Our findings point towards a continuum of functional states within WM, challenging the dichotomic active/latent view. Overall, this research advances our understanding of how we adaptively represent information in WM to guide goal-oriented behavior.</p>

<p><br />
<strong>Data and code availability</strong></p>

<ul>
  <li>
    <p>Data and Code have been deposited at <a href="https://osf.io/phxq4/">OSF</a></p>
  </li>
  <li>
    <p>The experimental plan was preregisteted at <a href="hhttps://aspredicted.org/qe5mt.pdf">AsPredicted</a>.</p>
  </li>
</ul>]]></content><author><name></name></author><category term="research" /><category term="behavior" /><category term="dissemination" /><category term="instructions" /><summary type="html"><![CDATA[üîì Open access]]></summary></entry><entry><title type="html">Do we always prepare in the same way?</title><link href="http://localhost:4000/blog/2023/chema/" rel="alternate" type="text/html" title="Do we always prepare in the same way?" /><published>2023-05-01T00:00:00+02:00</published><updated>2023-05-01T00:00:00+02:00</updated><id>http://localhost:4000/blog/2023/chema</id><content type="html" xml:base="http://localhost:4000/blog/2023/chema/"><![CDATA[<p>Today is a happy day!ü•≥ Our work (the first paper of Chema‚Äôs PhD!!) comparing <strong>top-down anticipatory representations</strong> in selective <strong>Attention</strong> and <strong>Expectation</strong> finally sees the light!</p>

<p><a href="https://t.co/DpJZ4h6XTf">üîì Open access</a></p>

<p>Being able to anticipate complex environmental information is crucial to achieve efficient behavior. But do we always prepare in the same way? üß†üîÆ
To answer that, <strong>we compared two (apparently) similar cognitive mechanisms</strong>: Selective Attention and Perceptual Expectations.</p>

<p>Selective Attention: is the stimulus <strong>relevant</strong> to my goals?
Perceptual Expectation: is the stimulus <strong>likely</strong> to appear?</p>

<p>We employed a cue-target task while recording EEG from healthy participants. In different blocks, participants had to select or expect faces or names.</p>

<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Fig1_chema.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<p>With Representational Similarity Analysis (RSA) we found that <strong>preparation</strong> is a complex phenomenon in which a <strong>cascade of events unfolds</strong>: from bottom-up cue coding, to top-down anticipated stimulus representation.</p>

<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Fig2_chema.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<p>Using MVPA, we found similar category (faces vs names) anticipation in both contexts. However, a classifier trained in one context was unable to generalize to the other! This, together with RSA suggests that <strong>anticipating relevant vs probable information is context-specific</strong>.</p>

<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Fig3_chema.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<p>All of this leads us to conclude that although humans are able to prepare efficiently for upcoming stimuli, they do so <em>differently</em> depending on their informational role. There are still lots of questions to answer, so stay tuned for more soon! üëÄüîç</p>

<p><br />
<strong>Data and code availability</strong></p>

<ul>
  <li>Code has been deposited at <a href="https://github.com/ChemaGP-UGR/AttExpLoc_EEG">Github</a></li>
  <li>Results have been deposited at <a href="https://osf.io/2rhjn/?view_only=1a729284b9d549b082ef725bc5081f3d">OSF</a>.</li>
  <li>Raw data are available online at <a href="https://openneuro.org/datasets/ds004502">OpenNeuro</a>.</li>
</ul>]]></content><author><name></name></author><category term="research" /><category term="EEG" /><category term="dissemination" /><category term="predictions" /><category term="preparation" /><summary type="html"><![CDATA[Today is a happy day!ü•≥ Our work (the first paper of Chema‚Äôs PhD!!) comparing top-down anticipatory representations in selective Attention and Expectation finally sees the light!]]></summary></entry><entry><title type="html">Measuring neural representations</title><link href="http://localhost:4000/blog/2023/ctt/" rel="alternate" type="text/html" title="Measuring neural representations" /><published>2023-01-09T00:00:00+01:00</published><updated>2023-01-09T00:00:00+01:00</updated><id>http://localhost:4000/blog/2023/ctt</id><content type="html" xml:base="http://localhost:4000/blog/2023/ctt/"><![CDATA[<p>Do you want to know more about how to use MVPA to address the activation level of specific neural representations? üß† Check our new paper on <strong>Canonical Template Tracking (CTT)</strong> in Frontiers in Neuroimaging.</p>

<p><a href="https://www.frontiersin.org/articles/10.3389/fnimg.2022.974927/abstract">üîì Open access</a></p>

<p>In this work, we described CTT: <strong>a multivariate approach that estimates canonical neural representations (or templates) from localizer tasks</strong>, to later track them in independent paradigms‚Äô data using either RSA similarity measurements or machine learning classifiers.</p>

<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<p>Despite the previous use of CTT in <a href="https://doi.org/10.1038/nn.3973">neuroimaging research</a> and its theoretical relevance for some <a href="https://doi.org/10.1038/s41583-022-00570-z">cognitive domains</a>, no methodological guidelines were yet available in the literature. We aimed to fill this gap!</p>

<p>In our paper, you will find <strong>recommendations</strong> on how to design localizer tasks from a multivariate perspective, a <strong>step-by-step tutorial</strong> on how to implement CTT analyses on spatial and temporally resolved datasets, and guidelines regarding results interpretation.</p>
<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/Fig3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<p>Do you want to give CTT a try? In the link below, you‚Äôll find Matlab <strong>scripts</strong> to perform different versions of the analysis on fMRI data. Also, the functions can be easily integrated in The Decoding Toolbox flow (check the analysis template).</p>

<p><a href="https://github.com/AnaPalenciano/Canonical_Template_Tracking">‚Äì <strong>GitHub repository with CTT code</strong></a></p>

<p><em>Want to read the actual paper?</em></p>

<p>Coming soon</p>]]></content><author><name></name></author><category term="research" /><category term="dissemination" /><category term="fmri" /><category term="representations" /><summary type="html"><![CDATA[Do you want to know more about how to use MVPA to address the activation level of specific neural representations? üß† Check our new paper on Canonical Template Tracking (CTT) in Frontiers in Neuroimaging.]]></summary></entry><entry><title type="html">How do we follow instructed actions?</title><link href="http://localhost:4000/blog/2021/instructions/" rel="alternate" type="text/html" title="How do we follow instructed actions?" /><published>2021-02-21T00:00:00+01:00</published><updated>2021-02-21T00:00:00+01:00</updated><id>http://localhost:4000/blog/2021/instructions</id><content type="html" xml:base="http://localhost:4000/blog/2021/instructions/"><![CDATA[<p><strong>PLEASE, READ THE TITLE AGAIN!</strong></p>

<p>Did you? If so, think about it for a second. Probably, it‚Äôs your first time in this website, you did not expect such subtitle, and still you did not have any problem in understanding and performing such action in just a few milliseconds. However, I could have asked you to do just about <em>anything</em>: touch your nose with your left pinky while looking to your right and singing <a href="https://www.youtube.com/watch?v=EHfx9LXzxpw">whatever song comes to mind</a>. Easy, right? this is just an example of how remarkably good humans are at following instructions,. But‚Ä¶ <strong>how does the brain does‚Ä¶ that?</strong></p>

<div class="row" style="text-align: center;">
    <div class="col-sm mt-0 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="https://media.tenor.co/images/b0aae6c2cf98ba2146231275e7479cfa/raw" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    
</div>

<h1 id="declarative-vs-procedural-representations">Declarative vs. procedural representations</h1>

<p>Let me start by mentioning a quite intriguing finding: humans are really fast at preparing to execute a novel instruction, and this rapid configuration towards action (or <em>implementation</em>) has pervasive effects on behavior and brain activity that have been largely reported in previous studies. How do current models account for these effects? The most prominent one puts forward a <em>serial-coding hypothesis</em>: first, instructions are represented in the brain in a <strong>declarative</strong> format (that is, a representation of the contents of the instructions, not specifically linked to action); then, during implementation, a <strong>procedural</strong> format takes over, optimizing representations for future actions. However, to what extent declarative and procedural representation organize brain activity during implementation is unclear. And.. that‚Äôs what this project was set out to find!</p>

<h1 id="canonical-template-tracking">Canonical template tracking</h1>

<p>To do so, we had human participants perform an instruction following task inside an MRI scanner. Importantly, our task allowed to tag, within each trial, instructions that were relevant for future behavior and instructions that were irrelevant.  But, how can we now what happens exactly during the implementation stage of our task? We tried to answer this question by creating <strong>canonical templates</strong> of procedural and declarative representations. That is, in two separate tasks, we tried to approximate to process-pure measures of procedural and declarative coding formats. Then, we tracked to what extent these templates were <strong>reinstantiated</strong> during implementation in the main task.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/mri.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="mri scanner" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/brain_scan2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Can we capture the activation of specific representations in the brain?
</div>

<h1 id="results">Results</h1>

<p>And what did we find? First, we found that templates of the relevant instructions of the trial were reinstantiated to a larger extent than irrelevant ones, suggesting that our tracking procedure was efficient. And what about the procedural vs. declarative question? Well, contrary to a hard interpretation of the serial-coding hypothesis, both declarative and procedural representations seem to explain unique parts of neural activity in relevant brain regions.  So, it does not seem to be the case that only procedural information explains the implementation stage, and rather, some declarative information might be needed as well. However, we did find some evidence that suggests a more <strong>crucial role of procedural representations</strong>. Specifically, the strength of these representations predicted behavioral performance: the more an instruction was coded in a procedural format, the faster and more efficient participants would later on exceute that instruction. And this was not the case for declarative information!</p>

<p>We interpret this result in the context of <em>output gating</em>. Similar to the idea of an input gate that limits what information enters working memory, some models propose an additional output gate that determines what information will drive behavior. We believe implementation might be a particular instance of output gating that engages relevant brain regions to transfer relevant content into a state that is optimal for behavior. But of course, further research is needed in this regard‚Ä¶ Stay tuned!</p>

<h1 id="resources">Resources</h1>

<p><em>Want to read the actual paper?</em></p>

<p><a href="https://web.archive.org/web/20210717050415id_/https://biblio.ugent.be/publication/8699558/file/8701388">Click here for the pdf version</a></p>

<p>Gonz√°lez-Garc√≠a, C., Formica, S., Wisniewski, D., &amp; Brass, M. (2021). Frontoparietal action-oriented codes support novel instruction implementation. NeuroImage, 226, 117608.</p>]]></content><author><name></name></author><category term="research" /><category term="dissemination" /><category term="instructions" /><category term="fmri" /><category term="representations" /><summary type="html"><![CDATA[PLEASE, READ THE TITLE AGAIN!]]></summary></entry></feed>