[
  {
    "objectID": "chapter2.html#introduction-to-neuroimaging-methods",
    "href": "chapter2.html#introduction-to-neuroimaging-methods",
    "title": "2  Neuroimaging techniques",
    "section": "2.1 Introduction to neuroimaging methods",
    "text": "2.1 Introduction to neuroimaging methods\n\n\n\n\n\n\nFigure 2.1: Different levels of analysis of brain functioning\n\n\n\nStudying cognitive function in the living human brain is a fascinating enterprise, and the advances in the last decades are impressive, due in large part to the development of non-invasive neuroimaging technologies and analysis methods. These methods, as we will see in the following pages, offer information about two core aspects of brain function: space and time. They offer information about the brain’s detailed physical structure, changes in levels of activation in specific localizations, and fast temporal information of changes in this activity. Also, interference devices allow creating short-lived virtual lesions in specific parts of the brain that provide crucial information about the causal links between brain and behavior.\nNowadays, however, there is no single neuroimaging method that allows us to see all relevant aspects of brain function at once. Rather, each of them provides optimal information regarding one dimension while downplaying others. The brain is a complex multi-level system and different methods have sensitivity only at some of these levels, that is, they offer partial information. Usually, the level of analysis targeted by the researcher determines the choice of method.\nThe brain works quite fast and with high spatial precision. It is frequent to classify neuroimaging methods according to their spatial and temporal resolution, or precision in these domains. In spatial terms, methods can be sensitive to information happening from the neuron level to the level of large-scale brain regions. Also importantly, some methods are able to offer temporal information at the millisecond range, whereas others have only sensitivity of seconds.\n\n\n\n\n\nFigure 2.2: Comparison of methods in terms of spatial and temporal resolution\n\n\n\n\nOther dimensions are also important: whether the device records brain activity or interferes/stimulates it, whether it generates damage when being used (non-/invasive) and the property of the brain that it measures (electricity/magnetism or blood flow).\n\n\n\n\n\nFigure 2.3: Characterization of different methods in Cognitive Neuroscience\n\n\n\n\nAlso important, neuroimaging methods do not allow to “see” the brain in action. The information we obtain from them mixes true data with measurement error and noise (random noise + confound factors), and the researcher has to tease these apart during data analysis and interpretation. And in addition, a crucial element in task-based Cognitive Neuroscience is proper task design. A well-designed paradigm carefully adapted to the neuroimaging method of choice is essential, as it allows interpreting the results in a meaningful way.\nWe will next cover the main methods employed in Cognitive Neuroscience, organized on the base of the brain properties that they measure, which in turn impacts their spatial and temporal resolution."
  },
  {
    "objectID": "chapter2.html#electrophysiology",
    "href": "chapter2.html#electrophysiology",
    "title": "2  Neuroimaging techniques",
    "section": "2.2 Electrophysiology",
    "text": "2.2 Electrophysiology\n\n\n\n\n\n\nFigure 2.4: Temporal course of voltage in a neuron’s action potential\n\n\n\nElectrophysiological methods measure the electrical activity that is inherent to brain function. Invasive methods measure neural electrical activity with high temporal and spatial precision, in neurons (single-cell), groups of them (multiunit recordings –MUA- and local field potentials, LFP) and regions (electrocorticography, ECoG). In addition, one of the methods most used in Cognitive Neuroscience is electroencephalography (EEG), a non-invasive technique that measures the combined electrical activity of thousands of neurons working together (synchronously).\nThe basis of communication between neurons is the action potential, in which the membrane potential of a neuron (which is the voltage difference between the interior and exterior of the cell) rises and falls rapidly. This spike travels through the axon of the neuron until in causes the release of neurotransmitters that impact other connected neurons. An action potential is the output of the neuron, and the unit that is measured by single-cell and MUA recordings.\nInputs to the postsynaptic neuron come from the spikes of presynaptic ones, which are pooled together in the dendrites of the receptive cell. This combined activity, when synchronous (i.e. happens at the same time), sums and generates extracellular electrical currents (generated by transient imbalances of concentrations of ions outside the neurons). These are measured at the local level as local field potentials, and when combined at a larger scale with ECoG and EEG.\n\n\n\n\n\nFigure 2.5: Pre and post-synaptic neurons\n\n\n\n\n\n2.2.1 Invasive methods\n\n2.2.1.1 Single-cell recordings\n\n\n\n\n\n\nFigure 2.6: Display of electrophysiological recording in a rodent\n\n\n\n\n\n\n\n\n\nFigure 2.7: Firing rates of a neuron when a light falls inside or outside its receptive field\n\n\n\nInvasive electrophysiological methods require the insertion of recording micro-electrodes inside the brain. Although tissue damage is minimized, it is unavoidable, and thus these methods are used most of the time with non-human animals. Very thin electrodes allow measuring the spikes (i.e. action potentials) of single neurons or groups of them (MUA), providing very useful information about how neurons respond to different kinds of stimuli and experimental tasks. The unit of measurement in these experiments is the number of spikes that neurons generate per unit of time during the manipulation, in comparison with the number of spikes happening during the baseline (when the experimental manipulation is not present). The assumption is that the higher the number of spikes, the larger the involvement of the cell in the condition under study. Figure 7 shows how the firing rate of a neuron (spikes/second) increases significantly when a bar of light is placed in its receptive field (which is the region of space to which the neuron responds), whereas this decreases when the light falls outside the receptive field.\n\n\n\n\n\n\nFigure 2.8: Place cells fire when the animal is in different regions of space\n\n\n\nThe ability to measure the response of neurons with such precision has significantly advanced our understanding of the mechanisms underlying brain cognitive function. A fine example is the work of O’Keefe, Moser and Moser (psychologists who received the Nobel price in 2014) in the description of place and grid cells. Hippocampal place cells respond when animals are in a certain spot in space (that is, they represent a certain location), and grid cells represent relative locations and distances between positions that the animal encounters, constructing a spatial map of the surroundings that is used for navigation. With electrophysiological recording tools, researchers are unraveling the computations that the neurons perform with spatial information in the service of behavior. Crucially, these investigations are also impacting our understanding of encoding and consolidation of memory of events, which also engage hippocampal areas in communication with cortical sites, and the role of sleep in these processes.\n\n\n\n\n\n\nFigure 2.9: Example of a recording in a neuron of the Inferotemporal Cortex during a working memory task.\n\n\n\nSingle-cell recordings performed in monkeys are also very informative of the mechanisms involving high-level processing, such as Selective Attention or Working Memory. For example, Joaquim Fuster, Patricia Goldman-Rakic and others showed that neurons in the lateral prefrontal cortex represent specific stimuli or locations, and that they remain active while animals maintain this information in their working memory (in absence of external stimulation) for future use. Other experiments performed by the group of Robert Desimone show that perceptual neurons in the inferotemporal cortex of monkeys also maintain this information during the delay period of a working memory task.\nIn rare occasions, single-cell recordings can be performed in humans, when electrodes must be placed inside the brain to find the location of damaged tissue that generates resistant epileptic seizures. In a classic example of this methodology, Quiroga and colleagues (2005) were able to record the response of single neurons located in the medial temporal cortex (hippocampus and surrounding structures) of humans while they viewed pictures of famous people and landscapes. Researchers found that some of these neurons had a highly specific preference for certain famous people and not others, that is, they had a high firing rate for their preferred person and almost no response to all of the other famous people presented. For example, they found these neurons for Jennifer Aniston or Hale Berry. Interestingly, Hale Berry neurons responded to her also when she was dressed as cat woman (with a mask that covered most of her face) and also to her written name. This suggests that these neurons have a highly specific and conceptual code for person identity.\n\n\n\n\n\nFigure 2.10: Example of firing rates of neurons in Quiroga and cols. (2005) experiment\n\n\n\n\n\n\n\n\n\n\nFigure 2.11: Fluctuations in excitability of neural populations correspond to windows of opportunity where the information can (or cannot) be transmitted between different neuronal pools\n\n\n\nAlthough the study of spiking rates of isolated neurons provides crucial information about how the brain works, there are other sources of complementary information that is also highly relevant. Neurons do not work in isolation, but rather they form coalitions of many neurons that respond or fire in a synchronous manner. These pools of neurons generate extracellular local field potentials, which fluctuate in up and down states that correspond to different degrees of excitability of the neural population. These are windows of opportunity for the transmission of information between populations of neurons, and conform the basis of communication between them. These local field potentials (LFP) thus represent local computations and are recorded also with invasive micro-electrodes placed in the extracellular space. They are often described in terms of the frequency of the oscillations, as we will see later for non-invasive EEG.\n\n\n2.2.1.2 Electrocorticography (ECoG)\n\n\n\n\n\n\nFigure 2.12: Example of an ECoG grid\n\n\n\nThe ECoG method uses grids of electrodes placed on the surface of the brain (which requires a previous craniotomy), and it is a method frequently used in presurgical evaluation of human patients with intractable epilepsy or other neurological conditions. This technique also measures LFP (synchronized postsynaptic potentials). Although its spatial resolution is smaller than LFP measured with invasive intracranial electrodes, this technique applied to humans offers an exceptional temporal and also quite good spatial resolution, and thus although its use is strictly limited, it offers very valuable information about cognitive function in the human brain.\n\n\n\n2.2.2 Non-invasive methods\n\n2.2.2.1 Electroencephalography (EEG)\nAt the beginning of the XXth century, Hans Berger set his mind to study the neural basis of psychic events, trying to find an explanatory mechanism for telepathy based on the brain’s electrical activity. He was able to measure this electrical activity by placing electrodes on the scalp of humans, and in 1929 he published a paper where he first described the EEG of people of different gender and ages. EEG can be characterized by its frequency, which is the speed of the electrical oscillations or number of cycles per second, expressed in Hertzs (Hz). Berger divided these oscillations into different frequency bands, named after letters of the Greek alphabet.\n\n\n\n\n\n\nFigure 2.13: EEG frequency bands\n\n\n\nEEG is often acquired using several electrodes at the same time, placed on the scalp. Classic montages use the so-called 10-20 system, and modern devices have extended the number of sensor up to 256 electrodes, to increase head coverage and facilitate source localization.\n\n\n\n\n\n\nFigure 2.14: Display of the 10-20 electrode location (left) and a high-density EEG recording system (right)\n\n\n\nAlthough EEG has been known since Berger’s discovery, for decades there was no clear understanding of the link between psychological function and frequency bands, other than gross associations between them and alertness states (e.g. Delta is most obvious in deep sleep, Alpha in drowsiness and Gamma in alert states).\n\n\n\n\n\n\nFigure 2.15: Averaging of the EEG to obtain ERPs\n\n\n\nAn important step forward in the use of EEG to advance knowledge about cognition in the brain came from the discovery of Event-Related Potentials (ERP). Here, the small changes in voltage triggered by external events (e.g. the onset of a stimuli, a button press, a decision between to options, etc.) are extracted from the background EEG data by presenting the same external event many times and averaging across presentations. The background EEG, which cycles between positive and negative voltage, is considered as noise, and as the events of interest appear unrelated to this, averaging causes background EEG to tend to zero due to the positive and negative voltages cancelling each other out.\n\n\n\n\n\nFigure 2.16: Example of the topographical distribution of voltage of the ERP peaks\n\n\n\n\nThe resulting ERP consists of a series of peaks of positive and negative voltages that appear with a different distribution (topography) on the scalp at different moments in time. ERPs are thus characterized by their polarity (with P for positive and N for negative), their timing in milliseconds and their topography (the location on the scalp where they appear). The literature on ERPs is full with experiments linking well-known ERPs with cognitive functions: the P1 and N1 appear over posterior electrodes and are labeled as perceptual potentials, linked to the processing of external stimuli; the frontal N2 with inhibition; the P300 appears on central channels and is linked to later response-related processes; the N400 to semantic processing.\n\n\n\n\n\n\nFigure 2.17: The arrangement of the neurons generating the ERP in relation to the recording electrode determines the polarity of the signal measured\n\n\n\nIt is important to note that the polarity (positive, negative) of ERPs has nothing to do with their function but rather to the orientation of the pool of cells that are its source (also known as dipoles). Electricity in groups of neurons can be understood in the same manner as a battery, which has a negative and a positive pole. If the source is oriented in a manner where the negative side is close to the scalp and the positive towards the inner part of the brain we will measure a negative peak, whereas it will be positive in the opposite situation.\n\n\n\n\n\n\nFigure 2.18: Example of an experiment using ERPs to study the effect of attention on stimulus visual processing\n\n\n\nERPs have been used extensively to test psychological theories and their underlying neural basis. For example, in the field of selective attention there is a long-standing debate of whether the beneficial effects on behavior caused by attending to something (in contrast to ignoring it) were due to attention improving the perceptual analysis of the information or rather its privileged access to consciousness and response effectors. To settle this, Steven Hillyard and others conducted several experiments where they contrasted the ERP of attended vs. ignored stimuli, showing that attended events generate larger P1 and N1, thus supporting the notion that selective attention enhances the perceptual representation of information.\n\n\n\n\n\n\nFigure 2.19: The N2 potential and its topographical distribution in a Go-NoGo task\n\n\n\nAnother fruitful approach is to use ERP as markers of potential differences between different groups of populations. For example, knowing that the N2 potential has been associated with inhibition, it can be used to compare the responses of children with and without attention deficit-hyperactivity disorder and see whether their N2 differ, which would be a suggestion that they have different inhibitory abilities.\n\n\n\n\n\n\nFigure 2.20: Evoked and induced brain activity\n\n\n\n\n\n\n\n\n\nFigure 2.21: Transformation of the EEG signal from the time to the frequency domain\n\n\n\nERPs are reflections of event-induced changes in the electrical signal that we can measure from the brain. However, there is much activity in the brain that is not triggered by external factors but rather takes place endogenously (remember the analysis of resting state data described in the previous chapter). The timing of this information is not locked to external events, and thus it is lost during the averaging used to extract ERP. An alternative and very useful approach are time-frequency analyses, which transform the EEG signal into different frequency bands and correlate these frequencies with the manipulation of interest.\nAs an example, using time-frequency analysis Mike Cohen showed that the amplitude of the Theta band over fronto-central electrodes was a better predictor of the individuals’ ability of inhibition during a flanker task than the corresponding N2 potential measured at the same time. This and other results suggest that time-frequency analysis represent a valuable addition to the electrophysiological analysis tools available in Cognitive Neuroscience.\n\n\n\n\n\n\nFigure 2.22: A specific pattern of EEG data can be explained by several different generators of neural activity\n\n\n\nWhereas EEG has excellent temporal resolution, as it offers information about neuron functioning in the millisecond range, it has poor spatial resolution. The electrical signal is fast conducted along the tissue and also gets distorted as it travels through the brain, meninges and skull, and thus the neural origin of the signal measured by the scalp electrodes is hard to locate. This is known as the inverse problem: for a given set of EEG data, there are many potential configurations of brain sources that could generate the same pattern of data. Several mathematical methods, known as dipole modeling, have been proposed to alleviate this problem. These are used in clinical settings (e.g. to localize the source of epileptic seizures with EEG) and also in research (to study the localization of effects observed with EEG data).\n\n\n2.2.2.2 Magnetoencephalography (MEG)\n\n\n\n\n\n\nFigure 2.23: The electricity linked to brain functioning generates magnetic fields that can be measured with sensors\n\n\n\nElectricity and magnetism are two forces intricately linked. MEG is the counterpart of EEG, as it measures the magnetic fields created by the electrical activity of pools of neurons working together. These magnetic fields, however, are very weak and need highly sensitive sensors to be recorded (called SQUIDs), which are surrounded by liquid helium to provide an optimal recording environment.\n\n\n\n\n\n\nFigure 2.24: A MEG device\n\n\n\nMEG has the same exceptional temporal resolution as EEG, and a better spatial one, because the magnetic fields suffer less distortion than their electric counterparts, and thus source localization with MEG has higher precision than when applied to EEG data. However, the cost of MEG is much higher than that of EEG, and thus its use is much more restricted.\nAs with EEG, MEG can only detect the activity generated by large pools of neurons that are oriented parallel to each other, because otherwise the positive and negative currents cancel each other out before reaching the scalp (this happens, for example, for brain nuclei such as the thalamus). This means that these recording devices do not detect part of the brain’s activity.\nOverall, neuroimaging techniques that rely on the electromagnetic properties of brain activity provide an excellent temporal resolution and a range of spatial resolutions, from the very good of single-cell and MUA recordings to the low spatial precision of EEG. Another excellent characteristic of these techniques is that they measure the activity of the brain directly, which is an important advantage compared to neuroimaging techniques that we will see next."
  },
  {
    "objectID": "chapter2.html#brain-imaging",
    "href": "chapter2.html#brain-imaging",
    "title": "2  Neuroimaging techniques",
    "section": "2.3 Brain imaging",
    "text": "2.3 Brain imaging\nThe quest for understanding how the brain supports cognitive function needs methods that allow studying its different parts separately and with good accuracy. Brain imaging methods allow this. They take advantage of the varying properties of different tissues that conform the brain (cerebrospinal fluid, white and grey matter, oxygen concentration in blood), and that react differently when stimulated through various means.\nInitially, clinical settings relied on Computerized Tomography (CT), which employs radiation. Skull and brain absorb radiation in different degrees and this is measured and used to plot them. This technique however has a rather poor spatial resolution as it does not allow distinguishing white from grey matter and see the details, and because of this has little use for research purposes. The development of Magnetic Resonance Imaging represented a huge step forward, initially for clinical purposes and soon after also for research.\n\n2.3.1 Magnetic Resonance Imaging (MRI)\nMRI provides images of the macrostructure of the brain in a safe, non-invasive manner with unprecedented spatial resolution, and it does so without any kind of radiation. Rather, it employs the magnetic properties of the different body tissues, and measures their differential response to radio-frequency stimulation to reconstruct images of the internal organs of the body (including, but not restricted to, the brain). The work of Lauterbur and Mansfield, based on previous discoveries by Raymour Damadian, led to the invention of this technology and to the award of the Nobel prize in 2003.\nThe MRI scanner generates a large magnetic field, which is always present and determines its strength. Scanners of 1.5 Tesla are common in hospital settings, 3T is the current most common strength for research purposes and some laboratories already work with 7T devices. These magnetic fields are very powerful, much larger than the magnetic field of the planet earth (0.0001 T).\nMRI takes advances of the susceptibility of hydrogen atoms to variations in the magnetic field, and to the fact that these atoms appear at varying concentrations in different body tissues. When a person enters the MRI, the hydrogen atoms of the body (spins), which are usually oriented at random, align with the strong magnetic field of the scanner. A radio-frequency coil applies excitatory pulses that disturb this alignment and displace the orientation of spins, and the MRI measures the energy that spins radiate during relaxation (when returning to the aligned state). As different tissues have varying concentrations of hydrogen, this information is used to reconstruct structural images of different kinds, being the T1 and T2 the most common structural images for research purposes.\n\n2.3.1.1 Morphometry\nStructural brain images are not only useful to study the anatomy of the human brain per se. These images are also used to extract indices of individual variability between different groups of people and study how these differ.\nVoxel-brain morphometry (VBM) is an analysis technique that looks for differences in gray matter volume in different brain regions. MRI images are constructed by voxels, which are volumetric 3D cubes of approximately 1mm3. In VBM, the voxels of T1 structural images are segmented into gray and white matter and cerebrospinal fluid, and the amount of gray matter per volume is used to predict individual differences in the cognitive function or mental faculty of interest, being this for example developmental stage, intellectual ability or skill in a certain domain.\nVBM has been used, for example, by researcher Eleanor Maguire to investigate how the extensive training in spatial navigation that London taxi drivers undergo changes the structure of their hippocampus, a brain structure tightly linked to this ability. Results of many investigations lend support to the notion that some individual differences in certain parts of the brain are related to the ability in the cognitive processes they support. Specifically, Maguire and her team demonstrated that the volume of the posterior hippocampus correlates with the number of years of practice in spatial navigation that drivers had.\n\n\n2.3.1.2 Diffusion tensor imaging (DTI)\nWhereas the brain’s gray matter corresponds to the neurons’ body, where information is processed, cognitive function also relies on the communication between brain regions, which is accomplished through the white matter, or the neurons’ axons. Research has shown that the integrity of the white matter bundles that connect different regions is sometimes related to the efficiency with which people are able to perform tasks that require the computation carried out by the connected areas. An index of this can be obtained with MRI scanning, again taking advantage of the susceptibility of hydrogen to strong magnetic fields to measure water diffusion.\nDTI employs scanning sequences that are sensitive to the movement of the hydrogen protons present in water. In a medium without restriction, water molecules move at random. In the brain, however, water cannot move freely due to the structure of the tissues, which limits the movement in specific directions. In axons, movement has a stronger direction perpendicular to them (due to the cell membrane and myelin sheath limiting the other directions). The strength of the direction of the movement (diffusion) is reflected in the so-called Fractional Anisotropy (FA) index, which varies between zero and one. Zero corresponds to equal movement in all directions whereas 1 reflects movement in a single direction. White matter fibers with higher integrity result in higher values of FA (as the movement is better contained), as well as more myelin (as the insulation is better). There are other factors unrelated to white matter integrity that also affect this index, however, such as the geometry or complexity of the path (as crossing fibers and higher complexity may reduce FA due to multiple directions existing in the same place). Careful interpretation of the results is needed to take these confounds into account.\nFA values are also used to reconstruct in 3D the fiber bundles that connect distant regions, though tractography. This method offers indexes of the integrity of long association fibers such as the arcuate, uncinate or longitudinal fasciculi. This is extremely useful in clinical settings, to diagnose damage to fiber bundles that does not appear in structural scans such as the T1. But in addition, it also offers invaluable information for research, as the integrity of the connectivity between brain areas often influences cognitive functions in healthy people. A large part of this research relates to plasticity mechanisms, as development and learning alter the myelin of the white matter tracts involved in specific cognitive functions.\n\n\n\n2.3.2 Functional imaging\n\n2.3.2.1 Positron emission tomography (PET)\nPET measures metabolic activity in the body using short-lived radioactive tracers. One of its major contributions to cognitive neuroscience is its ability to measure blood flow in specific parts of the brain, which relates to the function (not the structure) of the region. To do this, radioactive tracers (such as oxygen-15) are injected into the blood stream. When neurons are active, their metabolism increases, and this triggers an increase of blood inflow; when the blood is marked with radioactive tracers, these will appear in higher concentration in active regions, and the signal detected with the PET scanner will have higher intensity.\nPET was among the first neuroimaging methods with quite good spatial resolution, and was the technique initially used by Posner and Raichle when translating mental chronometry from experimental psychology into neuroscience research. Its use in research nowadays is very limited in scope, mainly for the drawbacks it presents. First, the injection of radioactive tracers is rather invasive and thus it cannot be used in children or elderly people. In addition, its temporal resolution is quite poor. The average duration of the tracers used is about 30 seconds, and thus PET only provides an image of the brain activation collapsed across this long temporal window. This is a very long time window, not fit to study fast mental processes.\n\n\n2.3.2.2 Functional MRI (fMRI)\nThe BOLD signal\nAs mentioned before, when a brain region is active its inflow of blood increases, and this generates the signal that is picked by the MRI. More concretely, fMRI is based on the BOLD (Blood Oxygen Level Dependent) signal, which reflects the ratio of oxyhemoglobin vs. deoxyhemoglobin in the blood. Hemoglobin is the molecule that transports oxygen in the blood, so the need for energy that neurons have when they work is partly supplied by an increase of oxyhemoglobin in the blood. This increase peaks about 5-6 seconds after the increase of activity. Oxygenated and deoxygenated blood have different levels of magnetic susceptibility, and this difference is the key to measure the BOLD signal with fMRI.\nThe change in time of the BOLD signal is called Hemodynamic Response Function (HRF), and this is the basic unit of measurement with fMRI. When a stimulus is presented, first there is an initial dip, or decrease in oxygenated blood (due to the extraction of oxygen from the blood by the neurons) and after 5-6 seconds there is an increase of oxygenated blood (named overcompensation), which returns to baseline levels around 20-25 seconds. Experiments that employ this technique analyze how well the BOLD patterns measured during the task correspond to the shape that would be expected if a region were activated by the presentation of the stimuli, and apply statistical methods to evaluate the extent to which brain areas activate in response to manipulations of interest.\nAs the previous paragraphs hint, fMRI measures neural activity in an indirect way. That is, it does not measure neural activity per se (as electrophysiological techniques actually do), but it measures the consequences that neural activity has on blood-derived signals. Although this difference may seem trivial, it has important consequences for the interpretation of the data and control of confounds.\nThe subtraction method\nSeparating the background activity of the brain from the part that is linked to the mental function of interest is not straightforward. The whole brain has constant blood and oxygen supply, and thus just observing brain activity per se shows most of the brain being active. To overcome this problem, Posner translated to the scanning environment the approach of mental chronometry and subtraction of conditions ideated by Donders. Within this subtraction approach, experiments are designed to compare the relative activations in two conditions, the experimental vs. the control. Bran activation is measured in both conditions and these are subtracted from each other: the areas that remain active are associated with the process(es) that differentiate the two experimental conditions.\nFor example, a researcher interested in localizing the parts of the brain that are involved in face processing, may present participants a set of human faces while they view them as their brain is scanned with fMRI. S/he could give them a task to keep their attention on the stimuli, such as judging if the images are presented in color or in black and white. If the researcher only acquires trials with faces present, s/he will find that most parts of the brain are active. The question is, which of those areas are involved in face perception per se and not in other bits not directly related to face perception, such as basic perceptual analysis and object contour detection, color processing, decision-making or motor responses? To isolate face-related activity, the researcher needs to find a control condition, which should contain all those processes not related to face perception. For example, the control condition may present colored masks of different patterns and colors, which are rather similar to faces, and ask participants to make the same decision and motor responses (e.g. color judgment) When this control related activity is subtracted from the activity observed during face perception, regions involved in face perception will remain but the common ones will be removed.\nFinding a perfect control condition, however, is not straightforward, as it is common that the differences between the two conditions are not exclusive to the process of interest. In the example above, faces are more likely to generate emotional reactions or aesthetic judgments than colored masks, which may affect the regions observed. The choice of control conditions always has to be considered carefully, and this information has to be taken into account during the interpretation of results.\nExperimental designs\nThe experimental conditions in the design can be arranged in different manners, and this choice has a large influence on the statistical power and temporal resolution of the results, among other things.\nIn Block Designs, stimuli belonging to the same condition are grouped and presented closely in time in blocks. These blocks have a relatively long duration (15-20 secs), and are presented in an alternating fashion with the control condition.\nBlock designs present a very high statistical power (i.e. they can detect subtle effects), and because of this they are the choice for typical localizers (e.g. localizing the areas underlying face processing). However, they have very low temporal resolution because the individual activity generated by each event in the block cannot be separated, and because of this they are not well suited to study typical cognitive processes such as memory retrieval.\nEvent-related designs are a solution to this problem. Here events of different conditions (experimental and control) are presented intersected or mixed, with time intervals of varying durations between them. These intervening time intervals of varying duration allow the application of mathematical tools (General Lineal Models, GLM) to extract the differential activations generated by the events.\nThese event-related designed are much more frequently used in all kinds of experiments in Cognitive Neuroscience, as they allow much more flexibility and are more easily adapted to typical trial arrangements in Cognitive Psychology. These designs allow, for example, to separate trials depending on whether the person was able or not to remember the information memorized, or to mix congruent and incongruent trials of a Stroop task. The main drawback is their lower statistical power compared to block designs, which makes them less sensitive to detect subtler effects.\nParametric designs are a subtype of event-related designs that avoid the need to perform subtractions between conditions. Here, the cognitive event of interest is manipulated in a continuous manner, and associations are drawn between brain activity and increases in the variable of interest, rather than categorical differences as in the subtraction approach. An example would be to manipulate the number of items that a person has to hold in mind during a Working Memory task, and to find the regions in the brain that increase their activity with the number of items.\n\n\n🚨Interpreting fMRI data🚨\n\nMaking sense of colorful brain pictures obtained with fMRI may seem straightforward, but it should not be taken lightly. From data collection to obtaining the images displaying brain activations, many pre-processing steps have to be performed on them. Among other things, data need to be corrected for distortions due to head movement, individual brains are “normalized” to match the shape and size of a standardized brain and data are blurred to conform to statistical assumptions. Then statistical analyses comparing the conditions of interest are performed, which require correction for multiple comparisons to avoid false positives. The colors depicted in the brain images are not direct neural activity, but rather regions with statistical values higher than the statistical threshold. And it always should be kept in mind that the resulting image depends on the experimental and control conditions manipulated.\nThere are some common assumptions during image interpretation that are not always held. First, given that fMRI is mostly sensitive to the input of an area (rather than its output) activations are not always unambiguously tied to excitatory mechanisms, but they could also relate to the area being inhibited. Also, a lack of increase of activation does not mean that the area is not relevant to task performance, and a decrease of activation does not mean that the area is not involved in the cognitive function studied. Several results relying on multivariate pattern analyses show that areas that show no increase of activation or even a decrease may contain information that is relevant to perform a certain task.\nImportantly, the methods described so far (electrophysiological and brain imaging) are correlational in nature, that is, they only reveal brain markers that covary with the manipulations of interest. But correlation does not imply causation, that is, these methods do not prove that the areas highlighted are necessary to perform the studied function. In the same way as the shade of objects is always present but does not have a causal role in the object’s function, the activations observed could be a consequence of other unknown factors that covary with our manipulation (such as how the light impacts objects in the domino’s example). To show that a region is necessary for a certain computation, it has to be proven that a lesion to that region impairs or disables that function. This type of evidence has been obtained studying the mental deficits of neuropsychological patients and employing interfering/lesion methods in healthy participants."
  },
  {
    "objectID": "chapter2.html#lesion-and-stimulation-approaches",
    "href": "chapter2.html#lesion-and-stimulation-approaches",
    "title": "2  Neuroimaging techniques",
    "section": "2.4 Lesion and stimulation approaches",
    "text": "2.4 Lesion and stimulation approaches\nLesion methods infer the function of a region (or cognitive mechanism) by removing it and studying the effect that this has on how the system works. For example, if damage to a region disrupts reading, but not speaking or perceiving, then it could be concluded that the region is specialized for some aspect of text processing. Disruption of brain function happens through natural damage in humans (strokes, etc.), elicited damage (e.g. animal models), or non-invasive temporary changes induced electromagnetically (TMS).\n\n2.4.1 Neuropsychology\nThis discipline has an experimental and a clinical side. In experimental terms, neuropsychology studies how naturally occurring damage in different parts of the human brain impacts the patient’s cognitive function. In addition to study single-case patients, where observations are restricted to specific patients, neuropsychologists also work with groups of patients that have suffered similar lesions.\nIn observations termed single dissociations, the researcher studies how a specific lesion damages a certain cognitive function. For example, a certain lesion may damage the reading of consonant letters but not vowels, which suggests that that region plays a role in processing consonants but not vowels. However, single dissociations evidence leaves other alternatives equally plausible. Following the example, what if processing consonants were more difficult than processing vowels, and this made that any lesion in the brain were more likely to affect consonants than vowels? To rule this out, researchers try to obtain double dissociations, where a group of patients with lesions in one site presents one profile of deficits and another group with a different lesion location presents the opposite profile. This way, the evidence linking these regions to their respective cognitive functions is stronger.\nAlthough neuropsychological research has significantly advanced our understanding of how the brain works, it also has significant limitations. First, as lesions occur naturally and have multiple different causes, so they are often blurry and differ significantly between patients. Also, lesions generate plastic changes in the brain, which may occur at different speeds, and thus alternative regions may replace some of the functions initially held by the lesioned area. Although this is a significant advantage from the clinical point of view, it hinders establishing links between regions and function. Methods that allow generating virtual non-invasive lesions in healthy participants represent valuable additions to the field.\n\n\n2.4.2 Transcranial Magnetic Stimulation (TMS)\nStimulation methods are frequently used in both basic and applied settings, that is, to study the brain’s cognitive function and also to aid in the therapy of various psychological and neurological disorders. TMS is used (under different stimulation protocols) both to induce virtual, short-lasting lesions on healthy participants and also to stimulate brain activity and promote plasticity in learning and neuropsychological rehabilitation.\nIn TMS, an electromagnetic coil (most of the times with an 8 shape) is placed close to the brain area of interest and it is used to influence the activity of this area with spatial and temporal precision. The TMS coil has wires inside that conduct electricity, inducing a magnetic field that through electromagnetic induction causes another electric current in the brain itself. The location of the coil can be determined anatomically (with bone landmarks or employing a structural MRI image of the individual participant, guided by a neuronavigation system) or functionally (e.g. activation of contralateral hand muscles, or eliciting delays in saccades by stimulating the Frontal Eye Fields).\nTMS stimulation is applied in pulses, and the protocol with which these pulses are administered determines the effect that the machine generates. These can be single or repetitive pulses, and repetitive pulses can be applied online (while the person is performing the task) or offline (before the person performs the task). Single pulses generally produce short-lived stimulation of the neurons (action potentials) in the targeted area, and are used for example to generate motor evoked potentials, or the perception of visual phosphenes (light flashes) when applied to the early visual cortex. Repetitive TMS (rTMS), on the other hand, has longer-lasting effects that extend after the period of stimulation. Here, the intensity, frequency and duration of the stimulation determines whether it has a facilitatory vs. inhibitory effect over neural activity. Repetitive 1 Hz TMS is used as inhibitory stimulation (i.e. to generate virtual lesions, mimicking the effects observed in neuropsychological patients). Higher frequencies can also facilitate neural processing, although there are many stimulation protocols with varying facilitatory or inhibitory effects.\nTMS has several benefits in comparison with neuropsychological patients. Its effects are temporary, so the application of TMS does not induce brain reorganization (in contrast to neuropsychological patients). This reversible nature means that lesions can be performed in within-subjects experimental designs, which increases experimental power significantly. Also, the effects of TMS are focal (1 cm or so), and the location of “the lesion” can be moved at will, which provides high precision. In addition, its use can be combined with EEG or fMRI, which increases significantly its utility. However TMS also has drawbacks: it can only be used to directly stimulate cortical brain regions (TMS only reaches tissue beneath the skull), and the spatial extent of the effect is not fully understood, as there is evidence that cortical pulses may also affect distant brain regions due to anatomical paths connecting them.\nThere are many experiments that support the utility and reliability of the effects of TMS on brain activity, and its additional usefulness when drawing causal links between brain and behavior. For example, TMS has been used to prove the plastic changes that the brain of blind people undergoes. Cohen et al. (1997) showed that TMS applied to the mid-occipital cortex (a classical visual region of the brain) of blind individuals disrupted their braille reading in comparison with a control condition (sham TMS) or the stimulation of a sensorimotor region. This pattern was reversed in sighted individuals reading braille, suggesting that the visual cortex is causally involved in blind readers when they use their sense of touch to read with their fingers. More recently, Katarzyna Siuda-Krzywicka et al. (2016) showed in a combined fMRI-TMS experiment that this plastic reorganization also happens to sighted participants after they learn to read braille. After 9 months of braille reading, participants in the experimental group (compared with a control group who did not undergo this training) showed increased activity of the Visual Word Form Area (VWFA, a region in the fusiform gyrus activated during sighted reading) when reading braille. In these participants, TMS applied to the VWFA decreased the accuracy of braille reading of words (but not pseudowords, a control condition). This shows not only that the brain undergoes plastic changes due to learning, but also that some of these changes are causally important for the effects of learning on behavior.\n\n\n2.4.3 Transcranial electrical stimulation (tES)\nThis technique applies small electrical currents to the human scalp with the aim of stimulating and facilitating the activity of the underlying brain region. There are different types of tES, with constant (transcranial direct current stimulation, tDCS) or alternating currents (alternating, tACS, and random, tRNS), which can be applied with different (low) intensities. tDCS is thought to affect neural excitability at the macroscopic level, with effects that seem to extend in time beyond the stimulation period through plasticity, whereas tACS is supposed to affect oscillatory brain mechanisms.\nIn tES, electrodes are placed on the scalp with different montages, which influence the spatial extent of the area affected by the current. The current flows among the electrodes, with electricity flowing from the anode (positive) electrode to the cathodal (negative) electrodes. Whereas the regions close to the anodal side receive excitatory stimulation, sites close to the cathodal ones seem to be inhibited.\nA large part of the literature employing tES is aimed at enhancing cognitive function through the effect of this method on cortical plasticity (e.g. in mathematical cognition, learning and memory, sleep, sports, etc. etc.), and the results have been somewhat mixed. Although the technique has shown promising results in several domains, it is also an area of high hype nowadays which is full of claims unsupported by solid scientific evidence.\n\n\n\n\n\n\nReflection questions 💭\n\n\n\n\n\n\nHow do electrophysiological methods differ from brain imaging methods in terms of what they measure and their spatial/temporal resolution? Consider the advantages and limitations of each approach.\nWhy is the “subtraction method” important in fMRI research? What are some potential challenges or limitations of this approach?\nCompare and contrast the insights gained from studying patients with brain lesions versus using TMS in healthy participants. What are the unique advantages of each approach?\nHow have advances in neuroimaging techniques contributed to our understanding of brain plasticity? Think of an example from the chapter that illustrates this.\nThink about the ethical considerations researchers must keep in mind when using different neuroimaging techniques, particularly those involving radiation or electrical stimulation."
  },
  {
    "objectID": "chapter1.html#what-is-cognitive-neuroscience",
    "href": "chapter1.html#what-is-cognitive-neuroscience",
    "title": "1  Introducing Cognitive Neuroscience: Concepts and History",
    "section": "1.1 What is cognitive neuroscience",
    "text": "1.1 What is cognitive neuroscience\nVery early on in our lives, we become aware of the world around us and also of inner thoughts and feelings, which together build our sense of ourselves as sentient organisms separate from the environment. Our conscious mind feels different from the physical world that surrounds us. During childhood, it is not uncommon to wonder how is it possible that a conscious intention to, for example, move our hand instantly triggers such a movement. How does my mind affect my body? And conversely, how does the body affect the mind? Humans have wondered about the nature of the mind, of the physical body and of their relationship since the dawn of our species. Although nowadays we are far from having comprehensive scientific explanations to these questions, hundreds of years of investigation have brought impressive discoveries and scientific advances, and many of these have laid the path to the field of Cognitive Neuroscience. In the same manner as our knowledge of how the mind and the brain work has been growing and improving over the centuries, theories and evidence in Cognitive Neuroscience are constantly being tested and refined, as it happens in any scientific discipline. This is reflected on the definitions or description of its object of study.\n\n\n\n\n\nFigure 1.1: There has been extensive debate on the philosophical and scientific frameworks to relate brain and mind/cognitive function\n\n\n\n\nInitially, the goal of Cognitive Neuroscience was set as the localization of cognitive processes in the brain. Using non-invasive neuroimaging techniques in humans, and also data from neuropsychological patients and disruption/stimulation devices, or invasive neuronal recordings and disruption/stimulation in non-human animals, Cognitive Neuroscience aims to localize which parts of the brain underlie processes described by Cognitive Psychology, such as Perception, Memory, Attention, or Emotion, among many others.\nThis definition, however, relies on two assumptions that are highly contended. First, the extent to which cognition in the brain is organized in a clearly localized manner is a matter of intense and, sometimes, polarized debate. As we will see in coming sections, there is no scientific basis to the notion that a single brain area is devoted to a unique cognitive process (e.g. occipital cortex to visual perception, frontal lobes to executive processes). Also, brains are highly complex and dynamic organs: neurons of different types are arranged in groups or coalitions, which cluster in brain areas and subcortical nuclei that in turn organize into networks of connected areas. Hence, the level of neural organization at which processes should be localized is unclear. Does e.g. perception correspond to the activity of single neurons, of coalitions of them, to regions within the occipital lobe, to the whole occipital lobe, or to this in connection with temporal and frontal lobes? Second in contention, the extent to which the current existing repertoire and understanding of psychological processes (e.g. Perception, Attention, Language…) is accurate is also a matter of debate. It should be taken into account that cognitive processes are hypothetical constructs that have been employed in Cognitive Psychology to explain the human mind; however, these are only working models and thus they could be partially mistaken. In this sense, current evidence does not support the notion of a strong equivalence between one brain region and one cognitive process. As an example, the occipital cortex is involved in visual perception, but this lobe is also recruited during imagination, learning, memory, attention, and even when blind individuals read Braille. Conversely, visual perception recruits regions of the occipital, temporal, parietal and frontal cortices. Taking all this into account, we should be wary of simplistic statements that localize mental functions in specific brain areas. The occipital lobe is involved in visual perception, yes, but the sole function of the occipital lobe is not perception, and explaining perception does not mean locating it solely on the occipital lobe. Drawing on a familiar assertion, that there is a fear center in our brain and that it is localized in the amygdala is an inaccurate statement. A more accurate assertion would be that the amygdala is involved in many mental functions, that include fear processing but also other categories of emotions, reward processing, learning and selection of relevant information, among others.\n\n\n\n\n\nFigure 1.2: It is common to see charts tagging brain regions with concrete mental functions. Although catchy and colorful, these descriptions are usually inaccurate and reflect oversimplifications of how the brain works.\n\n\n\n\nA more comprehensive definition of Cognitive Neuroscience would be that it is multidisciplinary scientific field that aims to explain how the brain supports cognition. Researchers in the field aim to provide physiological or mechanistic descriptions of how neural activity at different scales, being these isolated neurons, their coalition, brain regions and/or networks, give rise to (human) mental functions. Hence, rather than merely describing or linking specific brain regions with cognitive processes, an ulterior goal of the discipline is explaining how this happens, in mechanistic or algorithmic terms. Essential to this is the study of how neurons in different parts of the brain code or represent information, and how this information is transferred between different regions, that is, how communication among brain areas takes place in an effective manner.\nA scientific field that aims to bridge between two domains of such complexity such as the human brain and mind cannot rely on a single discipline, and because of this Cognitive Neuroscience is a multidisciplinary endeavor. Relevant fields include Psychology, Neuroscience, Biomedical and Signal Engineering, Philosophy of Mind and Physics, among others. The variety of sources of knowledge that along history have led to our discipline is a precursor of this."
  },
  {
    "objectID": "chapter1.html#historical-background",
    "href": "chapter1.html#historical-background",
    "title": "1  Introducing Cognitive Neuroscience: Concepts and History",
    "section": "1.2 Historical background",
    "text": "1.2 Historical background\n\n1.2.1 The mind-body problem\n\n\n\n\n\n\nFigure 1.3: Descartes contended that the interaction of mind and matter took place in the pineal gland of the human brain.\n\n\n\nThe intuition that the mind and body correspond to qualitatively different types of substances has accompanied humans for a long time. Attempts to explain our subjective mental experience, or qualia (e.g. the redness of the color red) as based on a physical substance (the body) are often rejected as implausible, given the belief that the mind (or spiritual soul) pertains to a reality that cannot be reduced to physical entities (such as the body). Still nowadays philosophers such as David Chalmers contend that whereas science will be able to eventually explain how the human brain performs mental mechanical functions, explaining why and how humans have qualia is the “hard problem” of consciousness. Many believe science will never be able to answer this question.\n\n\n\n\n\n\nFigure 1.4: Light can be understood as waves of continuous energy or as particles.\n\n\n\nRené Descartes (17th century) is the philosopher that best represents the mind-body Dualism, which claims that mind and body are composed by qualitatively different substances. Although the res extensa (matter) and res cogitans (mental substance) have different properties or qualities according to Descartes, they interact causally through the pineal gland in the brain. Dualism is still part of some current philosophical traditions and it is also embraced by several religions, but its relevance for a scientific discipline such as Cognitive Neuroscience is severely limited. Given the core assumption of Cartesian dualism that the mind pertains to a reality that is qualitatively different from the body, how could we explain and understand the mind by manipulating and measuring the body? Science relies on manipulation and measurement to understand its object of investigation, and philosophical approaches that locate the mind and body in the same reality are much better suited to study them.\n\n\n\n\n\n\nFigure 1.5: A portrait of the Duchess Margaret Cavendish.\n\n\n\nIn this line, Monism contends that mind and body are not distinct realities, but rather correspond to the same substance. A subtype of this current is the Dual-Aspect theory by Baruch Spinoza (17th century), where mind and brain are two different levels of explanation of the same unique phenomenon, which corresponds to the same reality (according to Spinoza, this reality was God). That is, the same phenomenon can be explained or understood in two different ways. This approach is usually presented in analogy with explanations of the physics of light, which can be explained as a wave or as particles (photons). Also in the 17th century, Margaret Cavendish, Duchess of Newcastle, argued against dualism by claiming:\n\nSensitive and rational matter […] makes not only the brain but all thoughts, conceptions, imaginations […] and whatsoever motions are in the head or brain.\n\n\n\n\n\n\n\nFigure 1.6: Philosopher Patricia Churchland\n\n\n\nAn additional philosophical approach that pertains to the goals of Cognitive Neuroscience is Eliminative materialism, or Reductionism, pioneered by the philosopher Patricia Churchland (XXI). This perspective contends that although currently we need psychological or mental descriptions of phenomena, eventually these will be eliminated and replaced by purely biological concepts once we acquire enough mature knowledge of brain function. Although this perspective has been criticized as radical and there are many who think that psychological concepts are essential to explain the biology of cognition, reductionists often refer to other fields of science, where initial explanative concepts were later eliminated as explanations improved (e.g. Phlogiston theory).\n\n\n1.2.2 Heart or brain?\n\n\n\n\n\n\nFigure 1.7: Epic of Gilgamesh\n\n\n\nSetting philosophical perspectives about the mind-body problem aside, a different but revealing note on our history is where in the body ancient thinkers located the human mind. Although nowadays it is accepted as obvious that the brain is the site of cognition, during many centuries the central site of emotion and thought was assigned to the heart. This belief was maintained along centuries despite the accumulation of evidence that pointed to the importance of the brain. Early notions on this can be found in texts written in what now is Iraq about 4000 years ago (see Figure 1.7), and in others in following cultures and world locations. The first written challenge to this heart-centered view was in ancient Greece (600-250 BCE), based on some rudimentary anatomy linked to the school of medicine where Hippocrates belonged to. However, the heart notion prevailed as self-evident, and was defended by many including Aristotle, who characterized the brain as a coolant system.\n\n\n\n\n\n\nFigure 1.8: Illustration of Galen’s public pig’s vivisection\n\n\n\nDespite the accumulation of evidence, it took 400 years since Aristotle to obtain decisive evidence of the role of the brain as support of the mind, through the work of Galen (born 129 CE in now Turkey) as anatomist studying the effect of injuries in the brain of gladiators. Galen conducted “lecture-commentaries” where he performed live experimentation on animals.\n\n\n\n\n\n\nFigure 1.9: Vesalius drawing of the human brain, with great detail in ventricles and little for the cerebral cortex\n\n\n\nFor example, to prove that the brain nerves were responsible of the production of voice, he tied a thread tightly around the laryngeal nerves of pigs and showed that the squealing of the animal ceased, and it returned when the ligature was loosened. Squeezing of the heart, on the other hand, did not prevent the generation of vocal sounds. On the basis of this and many other experiments, Galen was certain that the brain, and not the heart, was the core organ of thought. Despite all the evidence, the Aristotelian heart-centered explanation continued dominating the general opinion, whereas brain-based explanations placed the presence of animated spirits in the ventricles of the brain (which were created in the heart, and transported in the blood). In the XVIth century, the work of the famous Vesalius (father of modern anatomy) was based on the idea that the brain was the base of thought. In his book De Humani Corporis Fabrica, he drew ventricles in large detail but left the cortex underdefined and many times schematic. He, however, contended that the ventricles appeared to be “nothing more than cavities”. Interestingly, Vesalius noted that the extensive anatomical knowledge that he had gathered through dissection was not useful to explain how the body and brain actually worked, and that nothing could be told about the location of faculties in the brain. That is, Vesalius already noted that anatomy on its own cannot explain mental function.\n\n\n1.2.3 From mechanical forces to electricity\n\n\n\n\n\n\nFigure 1.10: Descartes’ depiction of how fluids moved from the foot to the brain and back to generate reflex-like movement\n\n\n\nAlong the XVIIth century, the idea that the brain was the seat of the mind slowly settled among the majority, in part due to the work of René Descartes (published posthumously due to his fear of the Catholic church). He popularized a model of mechanic forces or machines to explain simple human behavior (reflexes), where fluid animal spirits (generated by the pineal gland) moved rapidly in the nerves. For a while, explanations of brain function relied on mechanic forces moving or vibrating the animal spirits or fluids along the nerves of the body. However, these analogies of humans and machines met furious opposition from authorities of religion, and many of them were prosecuted and banned even when printed in anonymity.\n\n\n\n\n\n\nFigure 1.11: Illustration of Aldini’s experiments on human cadavers\n\n\n\nElectricity became a matter of public interest in the XVIIIth century, and it was soon realized that it could affect the body of any animal, including dead ones, and from here it was linked to previous explanations of vibrations of the animal spirit in humans. Luigi Galvani performed experiments conducting electrical currents on amputated limbs frogs and of other animals and showed that “animal electricity” was clearly manifested in the movement of the muscles. He also suggested that the mind affected the brain by this same electrical means. Later, his nephew Aldini performed experiments showing how currents induced with batteries generated coordinated movements in human cadavers, which provided stronger support for electricity as a source of complex behavior. He also used batteries to create pioneering electrical therapy on depressed patients. Years later (1850), Alfred Smee claimed that the brain was comprised of thousands of small electric batteries, and constructed theoretical neural networks with feedforward and recurrent connections among the batteries, and also applied this theory to the nature of human ideas and consciousness. The brain and bodies of humans and other animals worked by the same general principles, the difference being the number and organization of its electrical components.\n\n\n\n\n\n\nFigure 1.12: Smee’s neural networks using batteries as analogies\n\n\n\n\n\n1.2.4 Phrenology and mental function\nPhrenology (“study of the mind”), initially known as cranioscopy, was a very popular doctrine in the XIXth century that claimed that it was possible to determine someone’s personality by measuring the bumps of the scalp. Franz Gall and later Johann Spurzheim conceived the idea that human behavior and personality could be divided into different innate mental faculties, which each resided on different organs or parts of the brain, and that by measuring the size of the skull covering these organs their importance for each person could be determined. This theory, which despite its popularity was never accepted by academia (or by the Catholic church, for that matter), provided three insights that still today inform our understanding of the link between the human mind, brain and behavior. First, phrenological explanations focused on the brain and not the heart, claiming that “the brain is the organ of all the sensations and of all voluntary movements”. Second, the discipline put forward the localization of mental function in specific regions of the brain. And third, Gall contended humans and other animals shared most of the psychological faculties (only 8 of their 27 faculties were unique to humans, including e.g. wisdom and poetry).\n\n\n\n\n\nFigure 1.13: Portraits of Gall and Spurzheim, together with a phrenological head model\n\n\n\n\nAfter years of growth, phrenology wane due to lack of evidence for its tenets. One of their contenders, Flourens, performed countless experiments removing different parts of the brain of different animals and concluded that “the cortex, the seat of intelligence, was a unitary structure”, and that localization only applied to very basic physiological functions such as breathing or motor coordination. This tension between localization of function and brain equipotentiality still holds nowadays.\n\n\n1.2.5 Neuropsychology\n\n\n\n\n\n\nFigure 1.14: A portrait of Paul Broca\n\n\n\nIn 1861, the French surgeon Paul Broca claimed that there was a clear association between brain size an intelligence, based on supposed differences between races and also between men and women. He also described the brain of a deceased man with severe lesions in the left frontal lobe, which had been unable to speak for decades (only repeating tan-tan) but had otherwise normal mental faculties. Broca assembled several cases of speech loss or aphasia, all of them linked to lesions on the same brain region. The implication was that one area of the brain served a circumscribed brain function, that is, that mental function could be localized, as phrenologists had also claimed. Soon after, Carl Wernicke reported the case of a woman who could speak but did not understand language, which suggested that other regions were specialized in language comprehension. A highly unethical direct demonstration of localization was performed soon after by the surgeon Robert Bartholow, who electrically stimulated different regions of the cortical surface of the brain of Mary Rafferty, a patient with partial skull damage due to a severe ulcer (and who died soon after these experiments took place). Stimulation resulted in different behavioral consequences depending on the region, supporting compartmentalization of function on the human cortex. Since its beginning, the effects of circumscribed brain lesions on human behavior and cognition have been a source of invaluable information to understand the relationship between brain and mind.\n\n\n1.2.6 Behavioral Neuroscience\n\n\n\n\n\n\nFigure 1.15: Drawing of a Purkinje cell by Ramón y Cajal\n\n\n\nConverging evidence of cortical localization stem from the work of Fritsch and Hitzig, who employed delicate electrodes to stimulate with weak currents the cortex of anesthetized dogs and observed that different locations led to different movements. Ferrier complemented these experiments with interventions in monkeys that offered similar overall results. Apart from movement, he provided evidence supporting the localization of reflective faculties, such as attention. Up to this point, however, investigators had no model of how the brain worked, and many doubted about the ability of science to eventually understand the brain and higher human mental function, our how consciousness could emerge from brain matter.\nIn the XIXth century it was discovered that cells compose living organisms, and also the brain. Despite this large advancement, a major dispute took place regarding how these cells were organized in the brain. Although it was clear that in the body cells were discrete units bounded by membranes, Purkinje’s microscopic observations of the human cerebellum suggested that brain’s cells formed a single organic network. Thanks to the work of Ramón y Cajal employing the Golgi staining method, it was established that nerve cells were also independent units, which were labeled neurons. “The most subtly complicated machine to be found in all of nature” had found the units of its complex structural organization. Paired with the action potential (clarified by the work of Hodgkin and Huxley, 1939), these discoveries provided the units that could be manipulated and measured in response to external stimulation to study brain function, which is a crucial aspect for Cognitive Neuroscience.\n\n\n\n\n\n\nFigure 1.16: Simplified depiction of Hubel and Wiesel’s experiments with cats\n\n\n\nHubel & Wiesel (1959) measured the activity (action potentials) of neurons in the visual areas of cats while they were presented visual stimuli, and showed that neurons located in different regions responded to stimuli with different characteristics. With these innovative functional experiments, they were able to draw a map of visual selectivity in the occipital cortex. This line of work progressed with Allman & Kaas (1971) describing the topographical organization of the extrastriate cortex or Zeki describing the connections among visual areas and the selectivity of association areas such as V5. Years later, Newsome and colleagues (1989) showed how the information about motion represented by neurons in V5 affected decision-making of monkeys, pushing the study of high-level cognition to the single-cell level.\n\n\n1.2.7 Mental chronometry and Cognitive Psychology\nScience relies strongly on the ability to manipulate the object of study and to measure with precision what happens to this object in reaction to our manipulations. These are labeled as independent and dependent variables, respectively. Having the means to properly manipulate and to measure is as essential as having a clear definition of the object that we plan to manipulate and to measure. As we have seen in the previous section, the realization that mental function resides in the brain, and that neurons communicate information with electricity that can be measured in action potentials, defined a unit of measurement for the neural side of the story. In terms of the mind, however, the divisions put forward by phrenologists were anecdotal and lacked scientific rigor. How could cognition be manipulated and measured in humans?\nCognitive Psychology was sustained on the metaphor that human minds could be compared to computer software. Computers receive input, process the information according to a goal and generate an output. We could then give inputs to human (stimuli), study how they process the relevant information, and measure their reaction to this. In this information-processing framework , Milner (1978) proposed that mental complex operations such as perception, memory, language, attention, etc., could be divided into simpler ones, and these simpler processes could be studied separately. Along the years, several theoretical models have been build in Cognitive Psychology trying to explain how all these mental phenomena work, at the basic level, by designing tasks that tap into cognitive processes and measuring the response that humans give when confronted with them.\n\n\n\n\n\n\nFigure 1.17: Portrait of Donders\n\n\n\nMany of these tasks rely on mental chronometry, a strategy put forward by Franciscus Donders (1869). Here, the speed of responses (Reaction Time, or RT) of humans in reaction to stimuli is measured and compared across different conditions of experimental presentations. Donders measured the time that it took people to (1) detect a simple visual stimulus, and compared this to the time needed to (2) recognize the same stimuli and to choose between two of them. These are called experimental conditions. By comparing the relative times between these conditions (employing the so-called subtraction methodology) he could infer the time that mental processes took. For example, the subtraction of the detection time from the discrimination time allows the calculation of how much time it takes to make a visual discrimination. Mental chronometry has been continuously refined over the years, and together with accuracy, it represents one of the main sources of information employed to study mental processes. These processes represent the unit of measurement of cognition.\n\n\n\n\n\n\nFigure 1.18: Photograph of President Obama awarding Michael Posner the National Medal of Science\n\n\n\nAmong the many scientists that have contributed to Cognitive Psychology, Michael Posner has been a key figure to translate mental chronometry applied to behavioral data (with RT) to the study of cognitive processes in the human brain. In 1994, together with Michael Raichle he published the book Images of Mind, where he laid out their initial efforts to use mental chronometry to localize cognitive processes in the human brain. The logic was the same as with mental chronometry, but adding neuroimaging methodology while the participants performed the task. The brain activity that appears differentially between the two experimental conditions manipulated can be associated with the cognitive process that they isolate. Returning to the initial experiment of Donders, with his subtraction method we could localize which brain regions are involved in choice or decision-making, which is a high-level element of human cognition.\n\n\n1.2.8 Non-invasive neuroimaging\nAs stated above, the capacity to measure the object of study determines to a large extent the progress of its scientific understanding. Measuring the human brain is not an easy endeavor, and for many centuries its anatomy could only be ethically studied post-mortem. Also, knowledge about anatomy does not easily inform function. An essential ingredient in Cognitive Neuroscience are the recent methods that allow to measure the brain at work while participants are performing the tasks that have been developed in Cognitive Psychology for several decades, combining in a meaningful way brain and cognition.\n\n\n\n\n\n\nFigure 1.19: EEG measured by Hans Berger\n\n\n\n\n\n\n\n\n\nFigure 1.20: Seiji Ogawa\n\n\n\nThe first recording method that could be employed non-invasively with humans was electroencephalography (EEG), described by Hans Berger in 1929 while he was trying to study the physiological basis of psychic events (telepathy). As EEG relies on electrical oscillations triggered by neurons, it has a very good temporal resolution that is well fitted to the fast speed of cognitive events. A few decades later magnetic resonance imaging (MRI) was developed thanks to the work of Lauterbur and Mansfield (1973). This method can be used to obtain images reflecting the anatomy or structure of the brain with fairly good resolution (e.g. current structural brain images have 1x1x1 mm or even higher). Crucially, soon after positron emission tomography (PET, 1979) and functional MRI (fMRI, Ogawa, 1990) were developed, offering unprecedented information of increased blood flow to areas engaged during specific cognitive processes. Also, Transcranial Magnetic Stimulation (TMS, 1985) started to being used to briefly disrupt the activity of targeted brain regions, allowing the measurement of the causal effect of virtual brain lesions on complex human behavior. Altogether, these neuroimaging methods bring powerful unprecedented tools to investigate the brain basis of the human mind, an endeavor that many had thought inaccessible to science.\n\n\n1.2.9 Signal engineering for data analyses\nMeasuring brain activity non-invasively is essential for Cognitive Neuroscience, but being able to interpret the resulting data is also crucial. This is, however, not an easy task. The brain is a complex organ that receives loads of information from the senses, analyzes and transforms this information in many different ways depending on the task at hand, and generates an almost infinite repertoire of behavioral patterns. This happens at a very fast pace and through the interaction of many different brain areas. The data that reflects this is very complex and not interpretable straight away.\n\n\n\n\n\n\nFigure 1.21: Logo of the Statistical Parametric Mapping (SPM12) package, employed to analyze MRI and EEG data\n\n\n\nHence, the growth of the discipline goes hand in hand with the development of analysis methods that help to interpret the neuroimaging signal into meaningful bits. Signal engineers and other professionals have developed a myriad of such analysis strategies, many of which are freely available to the academic community. Well-known packages include EEG lab of Fieldtrip for EEG data, and SPM or FSL for magnetic resonance. Along these pages we have seen how knowledge has evolved from the idea that mind and brain are qualitative different substances to being able to measure and study the human brain while it is generating purposeful complex behavior. Whereas these advances have been astonishing, there is still much more we do not know."
  },
  {
    "objectID": "chapter1.html#opposing-views-of-brain-functioning",
    "href": "chapter1.html#opposing-views-of-brain-functioning",
    "title": "1  Introducing Cognitive Neuroscience: Concepts and History",
    "section": "1.3 Opposing views of brain functioning",
    "text": "1.3 Opposing views of brain functioning\n\n1.3.1 Localization vs. equipotentiality\nOne of the big questions when thinking about the relationship between mind and brain is the extent to which mental function can be localized in the brain, and we have seen examples of these two views along the historical foundations of the discipline. Far from being solved, nowadays there are scientist that pursue a highly localizationist strategy, trying to find the exact site of precise computations in the brain, whereas others lean towards non-localization and prefer to focus their analyses on highly interactive networks of brain areas. The fact is that there is evidence in support of both options, which could seem impossible at first glance. Localizing basic perceptual and motor functions, which rely on primary visual and motor regions, seems to be rather straightforward. In contrast, more complex cognitive functions, such as attention or memory, rely on many brain areas, including high-level associative brain regions, where localization is more diffuse.\nThus, it seems the extent of precise localization may depend on the specific operation under study: whereas basic mental functions seem to be processed in fairly modular and localized regions of the brain, high-level cognition seem to rely on the interaction of several areas that process and represent information in a highly abstract fashion. This difference could explain, at least in part, the seemingly different results obtained after lesions of brain regions in non-human animals and neuropsychological patients.\n\n\n1.3.2 Task vs. rest: A default mode of brain function\n\n\n\n\n\n\nFigure 1.22: Resting metabolism of the brain, heart and liver\n\n\n\nUntil recently, the study of human brain activity was dominated by the reminiscent computer analogy, where different stimuli were presented and participants were asked to perform multiple tasks on them. That is, brain activity was measured as a reaction to stimulation, which agreed with the view of the brain as a reactive organ. There were, however, several pieces of evidence that do not fit with this interpretation and point to the existence of intrinsic brain operations that are not task-related. The brain is also a reflexive organ, with a large proportion of intrinsic activity unrelated to task demands. First, although the brain represents only 2% of the total body weight, it consumes 20% of all body energy. Of all this energy, a large portion ( 60 - 80%) is related to glutamate cycling, that is, neural signaling. However, task performance only explains 5% of all this energy consumption, whereas the remaining is unexplained. That is, the majority of the brain’s energy consumption is devoted to neural signaling that is functionally relevant but is independent of the task that the person is doing: this is known as intrinsic brain activity.\nIntrinsic activity is evident in neuroimaging recordings such as EEG, which shows oscillatory brain activity of different speeds that changes with time across the whole brain. For many years, however, it was assumed that most of this activity corresponded to noise , was treated as such and eliminated from the analyses as irrelevant.\nEmploying fMRI data, Bharat Biswal was the first researcher (then an engineer PhD student) to claim that the so-called noise was not such, but rather represented the activation of intrinsic brain networks, that is, regions of brain that were always activating in a coherent manner. This coherence is reflected in the correlation of activations between different regions: if one region increases its activation, so does the other, and in the same manner, both regions decrease their activity in a similar way. Analyzing the signals that came from the scanner, Biswal was able to show the existence of coordinated brain activity in sensorimotor regions of the two hemispheres, and also diverse regions linked to language or visual processing.\n\n\n\n\n\nFigure 1.23: Display of the coherent activity of the precuneus (yellow) and medial frontal cortex (orange) along time\n\n\n\n\nMarcus Raichle was also one of the pioneers in this field. He reported the first observation of the so-called Default-mode network (DMN), a network of brain areas (including regions of the medial prefrontal, posterior parietal and medial temporal cortices, and also the precuneus) that increase their activity when the person is at rest in the scanner (i.e., performing no task) and also shows coherent brain patterns of activation. Such coherent activations are also observed during anesthesia, sleep and in non-human animals, which speaks to the robustness of the phenomenon.\nFurther research has shown that the brain’s intrinsic activity contains signatures of many other networks apart from the DMN. These networks found at rest are strikingly similar to those involved during the execution of tasks of different nature. This strongly suggests that regions that tend to co-activate during task execution also connect when the brain is “at rest”, forming the brain’s functional backbone.\n\n\n\n\n\nFigure 1.24: Intrinsic brain networks in the human brain\n\n\n\n\nChanges in intrinsic network connectivity have been related to development, neurodegenerative diseases and also several psychiatric diseases, and the field is rapidly expanding with the goal of using activity in these networks as potential diagnostic tools to predict future mental dysfunction."
  },
  {
    "objectID": "chapter1.html#core-experimental-questions-in-cognitive-neuroscience",
    "href": "chapter1.html#core-experimental-questions-in-cognitive-neuroscience",
    "title": "1  Introducing Cognitive Neuroscience: Concepts and History",
    "section": "1.4 Core experimental questions in Cognitive Neuroscience",
    "text": "1.4 Core experimental questions in Cognitive Neuroscience\nThe field of Cognitive Neuroscience gathers professionals from multiple disciplines, including experimental and clinical psychologists, neuroscientists, signal and computer engineers and physics, and this variety of professionals usually lead to research programs focused on different research questions. Many of these, however, can be grouped in a few core families of experimental questions.\n\n1.4.1 Characterization of Cognitive Functions\nSometimes researchers use neuroimaging tools to advance the knowledge about psychological processes or theories per se, and the information gained about the brain is secondary to this. That is, they use neuroimaging technologies to measure brain activity during the performance of their processes of interest and use their result to draw inferences about how cognition works. An example could be of an investigator who wants to study if verbal language perception also involves motor representations. The activation of brain motor regions during a purely perceptual task would provide support for this hypothesis, whereas the lack of it would not.\n\n\n1.4.2 Localization of cognitive processes\n\n\n\n\n\n\nFigure 1.25: Experimental conditions and subtractions in Posner and Petersen’s 1989 PET experiment\n\n\n\nExperiments where the main goal is to learn where in the brain a cognitive process lies are also frequent. Here the researcher uses cognitive tasks and usually subtraction inferences to investigate which areas increase their activation during one condition compared to another control condition. This endeavor requires neuroimaging methods with good spatial resolution, such as the fMRI. In a classic example, Posner and Petersen (1989) localized the regions involved in different stages of language processing (viewing words, reading them aloud, generating verbs reflecting their potential use, e.g. hammer – pound) by subtracting the average brain activity between them. They showed that visual word perception engaged the occipital and ventral temporal cortex, reading them aloud engaged motor areas, and left inferior frontal regions supported verb generation.\n\n\n1.4.3 Computations and representation of information\n\n\n\n\n\n\nFigure 1.26: Display of a method for calculating how similar are the brain patterns of activation for different categories of animals, which is used to study how the dimension of animacy organizes activations in the ventral temporal cortex\n\n\n\nIn addition to knowing that an area is involved in a certain mental function (e.g. ventral temporal cortex in visual perception), a further question is to learn how neurons represent the information, that is, what is the neural code for this. For example, researchers investigate how neurons represent specific objects or their categories: is it that one neuron responds only to a certain stimuli, or the same neuron responds to several different objects with varying strength? Another line of research aims to discover which are the basic dimensions (e.g. stimulus orientation, brightness, complexity, animacy…) that guide how the information is coded in the brain.\n\n\n1.4.4 Networks: Communication of information between brain areas\n\n\n\n\n\n\nFigure 1.27: Example of brain nodes and their connections (edges), forming networks\n\n\n\n\n\n\n\n\n\nFigure 1.28: Diffusion tensor imaging (DTI) image reconstruction\n\n\n\nIt is well known that many cognitive functions take place through the interaction of populations of neurons located in different parts of the brain. This means that neurons in a certain region process information and the result is passed on to other regions, and so forth. The set of brain regions and connections between them that work together to generate mental functions are called large-scale brain networks. The properties of these networks as a whole can be studied using models from the mathematical discipline of Complex Systems, which characterizes their properties in terms of how efficient they are, the level of modularity in their function, and many other factors. Functional networks are studied both when the person is performing tasks and also when they are “at rest”. An important addition to these are structural networks, that provide information regarding the white matter fibers that anatomically connect the different brain areas, and that constrain the scope of their functional interactions.\n\n\n1.4.5 Individual differences\nHumans differ in many different psychological characteristics and mental abilities, such as extraversion, intelligence or meditation skills. Brains can also be compared in terms of development, and mental disorders such as schizophrenia. Neuroimaging data can be used to compare groups of individual differing in these characteristics, with the goal of studying the underlying functional and structural brain differences that correlate with the differences of interest. These results in turn can aid to better understand these phenomena both at cognitive and neural levels."
  },
  {
    "objectID": "chapter1.html#applications",
    "href": "chapter1.html#applications",
    "title": "1  Introducing Cognitive Neuroscience: Concepts and History",
    "section": "1.5 Applications",
    "text": "1.5 Applications\nCognitive Neuroscience is rapidly increasing our knowledge about how the brain supports cognition. As explained above, this increases knowledge about the brain, but also of the cognitive processes investigated or other domains related to psychology, such as education. But in addition, this knowledge is being applied to diverse fields, including the following:\nDiscovery of early biomarkers of developmental, mental or other neurological diseases: There is a large interest in finding markers or indices in the profile of brain activations and/or structure that can be used to detect these problems as early as possible, to aid in their diagnosis and also to suggest potential targets for intervention. Although this field is of high interest to society due to the large benefits it may bring, there is still much to learn to be able to obtain biomarkers that are reliable at the individual level, due to current limitations in the methods and analyses available.\nIntervention of disorders through neurofeedback: The technique of neurofeeback allows humans to learn to control certain aspects of their brain function. Through neurofeedback (usually implemented using EEG or fMRI), participants receive online information about a certain index of brain activity of interest and receive online feedback about their progress in modulating such index. In a slow trial-and-error process, a large proportion of participants become able to alter these indices, although the underlying mechanisms of this learning are not fully clear. In addition, currently there is little consensus on which brain markers should be used as targets for neurofeedback in different disorders (as the underlying biological causes of these disorders are not fully clear).\nGeneration of effective brain-computer interfaces (BCI): The field of BCI has a large history in Neuroscience, with the goal of building mechanisms to aid people with disabilities to communicate, regain control of their limbs or ameliorate symptoms of diseases (e.g. like deep neural stimulation in Parkinson patients). More recently, there are attempts to build BCI with more advanced capacities, such as using a brain interface to type directly into the phone. However, most of these are far from having a solution to all the inherent difficulties associated with this goal."
  },
  {
    "objectID": "chapter1.html#neuro-hype",
    "href": "chapter1.html#neuro-hype",
    "title": "1  Introducing Cognitive Neuroscience: Concepts and History",
    "section": "1.6 Neuro-hype",
    "text": "1.6 Neuro-hype\nOverall, there is tendency to think that research about the brain more “scientific” or solid than research about the human mind, but this is only a delusion generated by mental biases. Several experiments have shown that presenting colorful brain pictures next to the same set of assertions increases the ratings of the readers on credibility and appeal of the contents. The increased allure of brain images also seems to extend to related words, such as “neuro”. Unfortunately, this has led to the emergence of pseudo-scientific fields where the word “neuro” is attached to many words without adding actual meaning to the original, in an intent of making it more appealing to the public. Among many others we can find neurocoaching, neuropsychoanalysis, neuroleadership, neuromeditation, neurodrinks or neurogum.\n\n\n\n\n\nFigure 1.29: Neurobollocks\n\n\n\n\nAlthough the scientific advances in the field of Cognitive Neuroscience are enormous, unfortunately it is also quite common to find areas that oversell the results to the lay public, and generate misinformation and erroneous interpretations. This is also often made worse by press releases looking for click baits. For a non-specialized audience, it is difficult to spot oversold claims about the potential implications of neuroscientific findings. As we will see along the course, there are many things we still do not know about how the brain actually works. In the same way as psychologists cannot “read minds”, neuroimaging cannot “see brains”. We should be cautious and wary of assertions that claim e.g. to know what is wrong with the brain of schizophrenics or the definite solution to deficits of attention with neurofeedback."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cognitive Neuroscience",
    "section": "",
    "text": "Preface\nA few words about this book.\n\n\n\n\n\n\nDisclaimer\n\n\n\nThis material has been elaborated for the sole use of the Cognitive Neuroscience undergraduate course of the Universidad de Granada, years 2021-25. Please do not share without permission."
  }
]