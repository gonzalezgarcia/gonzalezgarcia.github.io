@preprint{ciprianiPeripheralSpatialRetroCues2025,
  title = {Peripheral Spatial Retro-Cues Trigger Automatic Retrieval of Working Memory Representations},
  author = {Cipriani, Germán A and Martín-Arévalo, Elisa and González-García, Carlos and Lupiáñez, Juan and Botta, Fabiano},
  year = {2025},
  journal={PsyArXiv},
  doi = {10.31234/osf.io/swdjx_v1},
  pdf = {https://osf.io/preprints/psyarxiv/swdjx_v1/},
  urldate = {2025-10-31},
  abstract = {Attention shapes how different types of information are maintained and retrieved from working memory (WM). Previous research examined whether the voluntariness of attention interacts with the type of content in WM using central arrow retro-cues, but found no such interaction. However, central and peripheral cues engage attention through different mechanisms: evidence from external attention shows that peripheral cues are more effective in triggering automatic orienting. Determining whether this distinction influences how attention modulates perceptual and semantic WM contents is essential for clarifying how voluntary and involuntary mechanisms operate on internal representations. In this pre-registered study, 100 participants completed two retro-cueing tasks in which peripheral retro-cues directed voluntary or involuntary attention toward perceptual (gray vs. sepia colors) and semantic (natural vs. artificial categories) features of real-world stimuli competing in WM. Reaction time and accuracy were analyzed using hierarchical drift-diffusion models. Results showed, first, that attentional voluntariness did not differentially affect perceptual vs. semantic WM contents, replicating a previous finding. Second, drift rates revealed retro-cueing effects for both voluntary and involuntary attention: voluntary attention produced stronger effects, primarily driven by costs, whereas involuntary attention yielded smaller effects, mainly driven by benefits. Third, non-decision times showed a similar pattern—larger effects (benefits and costs) for voluntary attention, and smaller, benefit-based effects for involuntary attention. Crucially, this involuntary modulation contrasts with previous findings using central retro-cues, where no such effect was observed. Together, these findings suggest that, prior to decision making, peripheral spatial retro-cues more effectively recruit involuntary attention, automatically reactivating WM representations when cue locations overlap with memoranda. Moreover, the results strengthen the view that voluntariness does not interact with the type of WM content when perceptual and semantic features compete for representation.},
  award={This is a **preprint**! [Read more](https://en.wikipedia.org/wiki/Preprint)}, 
  award_name={preprint},
 } 
,
@preprint{völler_2025,
 title={From sudden perceptual learning to enduring engrams: A representational perspective},
 html={osf.io/preprints/psyarxiv/39npk_v1},
 doi={10.31234/osf.io/39npk_v1},
 journal={PsyArXiv},
 author={Völler, Johannah and Linde-Domingo, Juan and Ortiz-Tudela, Javier and González-García, Carlos},
 year={2025},
 month={Sep},
 pdf = {https://osf.io/39npk_v1/download/},
 abstract = {Sudden perceptual learning refers to the abrupt disambiguation of an initially ambiguous stimulus. Despite the limited encoding time, these brief perceptual experiences transform into enduring memory engrams. Still, a comprehensive framework of why these memories are so long-lasting and their neural underpinnings, in particular the role of the hippocampus, is currently lacking. Here, we build on the apparent connection of sudden perceptual learning with long-term memory to outline how a representational perspective may help to overcome current limitations, similar to other areas of memory research. In short, we claim that sudden perceptual learning triggers initial prediction errors across the hierarchy, including strong higher-level (semantic) ones. Once a solution is found, the formerly ambiguous image can be connected to previous schemas and a disambiguation cascade of prediction error minimization is triggered, starting with semantic prediction errors. As a consequence, these events lead to low-dimensional representations that show signs of early semanticization, thereby favouring semantics over perceptual details. In sum, we propose that multiple memory traces are simultaneously encoded during sudden perceptual learning, and while low-dimensional representations engage neocortical structures, high-dimensional, episodic representations require the hippocampus. This perspective offers a promising framework to advance research on sudden perceptual learning and related phenomena.},
 award={This is a **preprint**! [Read more](https://en.wikipedia.org/wiki/Preprint)}, 
  award_name={preprint},
},

@preprint{Padezhki2025.07.18.665374,
	author = {Padezhki, Ivan and Linde-Domingo, Juan and Gonzalez-Garcia, Carlos},
	title = {Dynamic prioritization reshapes neural geometries for action in human working memory},
	elocation-id = {2025.07.18.665374},
	year = {2025},
	doi = {10.1101/2025.07.18.665374},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Prior work has shown that control brain regions encode upcoming novel instructed actions. Similarly, visual working memory (WM) representations can reflect different priority states. However, it remains unknown whether the priority status of WM-guided novel actions similarly modulates their neural coding format, and how such dynamics unfold over time. We addressed these questions using EEG while human participants performed two consecutive choice reaction tasks. At the start of each trial, participants encoded two novel stimulus-response (S-R) mappings. A cue then indicated whether these mappings would be relevant immediately ("current" condition), later after an intervening task ("prospective"), or after a free delay ("delayed"). Using multivariate pattern analysis, we found that the S-R category was decodable in all conditions during relevant time windows. Critically, pattern similarity analyses revealed that while mere maintenance demands allow for temporary preservation of neural codes (i.e., between current and delayed trials), shielding from interference (i.e., prospective trials) induced significant alterations to the neural code. Further exploration of the representational geometry revealed that priority status gained prominence dynamically over S-R category coding when preparing for such shielding demands. Importantly, some of these changes emerged anticipatorily, prior to target onset. Overall, our results show that, similar to visual WM, the priority of intended actions dynamically and anticipatorily reshapes their neural format. They further reveal how different demands induce content geometries compatible with previously proposed coding schemes, and that such representational changes can be implemented flexibly in time.Competing Interest StatementThe authors have declared no competing interest.MCIN/AEI/10.13039/501100011033, PID2020-116342GA-I00, RYC2021-033536-I, PID2023-151104NA-I00, RYC2021-033940-I, CEX2023-001312-MUniversity of Granada, https://ror.org/04njjy449, UCE-PP2023-11},
	html = {https://www.biorxiv.org/content/early/2025/07/23/2025.07.18.665374},
	pdf = {https://www.biorxiv.org/content/early/2025/07/23/2025.07.18.665374.full.pdf},
	journal = {bioRxiv},
  award={This is a **preprint**! [Read more](https://en.wikipedia.org/wiki/Preprint)},
  award_name={preprint},
}
,

@preprint{Linde-Domingo2025.05.28.656283,
  title = {Determinants of Visual Ambiguity Resolution},
  year = {2025},
  journal = {BioRxiv},
  author = {{Linde-Domingo*}, Juan and {Ortiz-Tudela*}, Javier and Voeller, Johannah and Hebart, Martin N. and {González-García}, Carlos},
  year = {2025},
  journal = {bioRxiv},
  html = {https://www.biorxiv.org/content/10.1101/2025.05.28.656283v1},
  pdf = {https://www.biorxiv.org/content/early/2025/05/29/2025.05.28.656283.full.pdf},
  publisher = {Cold Spring Harbor Laboratory},
  doi = {10.1101/2025.05.28.656283},
  abstract = {Visual inputs during natural perception are highly ambiguous: objects are frequently occluded, lighting conditions vary, and object identification depends significantly on prior experiences. However, why do certain images remain unidentifiable while others can be recognized immediately, and what visual features drive subjective clarification? To address these critical questions, we developed a unique dataset of 1,854 ambiguous images and collected more than 100,000 participant ratings evaluating their identifiability before and after seeing undistorted versions of the images. Relating the representations of a brain-inspired neural network model in response to our images with human ratings, we show that subjective identification depends largely on the extent to which higher-level visual features from the original images are preserved in their ambiguous counterparts. Notably, the predominance of higher-level features over lower-level ones softens after participants disambiguate the images. In line with these results, an image-level regression analysis showed that the subjective identification of ambiguous images was best explained by high-level visual dimensions. Moreover, we found that the process of ambiguity resolution was accompanied by a notable decrease in semantic distance and a greater consistency in object naming among participants. However, the relationship between information gained after disambiguation and subjective identification was non-linear, indicating that acquiring more information does not necessarily enhance subjective clarity. Instead, we observed a U-shaped relationship, suggesting that subjective identification improves when the acquired information either strongly matches or mismatches prior predictions. Collectively, these findings highlight fundamental principles underlying the mapping between human visual perception and memory, advancing our understanding on how we resolve ambiguity and extract meaning from incomplete visual information.},
  elocation-id = {2025.05.28.656283},
  award={This is a **preprint**! [Read more](https://en.wikipedia.org/wiki/Preprint)},
  award_name={preprint},
},



